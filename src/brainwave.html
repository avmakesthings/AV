<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">
    <link rel="icon" href="assets/img/favicon.ico">

    <title>AV | Brainwave  </title>

    <!-- Bootstrap core CSS -->
    <link href="assets/css/bootstrap.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="assets/css/ionicons.min.css" rel="stylesheet">
    <link href="//netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap-glyphicons.css" rel="stylesheet">   
    <link href="assets/css/superslides.css" rel="stylesheet">     
<!--     <link rel="stylesheet" href="assets/css/nivo-lightbox.css" type="text/css">
    <link rel="stylesheet" href="assets/css/nivo-themes/default/default.css" type="text/css"> -->
    <link href="assets/css/style.css" rel="stylesheet" type="text/css">
    <link href="assets/css/mediaqueries.css" rel="stylesheet" type="text/css">


    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <script src="assets/js/ie10-viewport-bug-workaround.js"></script>

    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  </head>

  <body data-spy="scroll" data-offset="0" data-target="#theMenu">
	

    <!-- ********** HEADER ********** -->

    <div class="logo" id="logo-top">
        <a href= "index.html">
          <img src="assets/img/common/AV_logo_black.png" class="logo_size" alt="AV"  style="max-height:80px!important;">
        </a>
        <nav class="menu" id="theMenu">
          <div class="menu-wrap navbar-collapse">
            <i class="ion-android-close menu-close"></i>
            <a href="index.html" class="smoothScroll">Home</a>
            <a href="index.html#about" class="smoothScroll">About</a>
            <a href="work.html" class="smoothScroll">Work</a>
            <a href="explore.html" class="smoothScroll">Other</a>     
            <a href="index.html#contact" class="smoothScroll">Contact</a>
          </div>
          <div id="menuToggle"><i class="ion-navicon"></i></div>
        </nav>
    </div>

<!--     <section id="home"></section> -->
    <div id="brainwave">
      <div class="container">
        <div class="row centered">
          <div class="col-md-8 col-md-offset-2">
            <h1>BRAINWAVE</h1>
            <h4>UX research. Interaction design 
            </h4>       
            <h6>A Master’s of Architecture thesis that investigated the possibilities of using Brain Computer Interfacing as an input modality for automated environments.</h6>            
          </div>
          <div class="go aligncenter">
            <a href="#proj" class="smoothScroll "><i class="ion-android-arrow-dropdown" style="font-size:60px;"></i></a>
          </div>
        </div>
      </div><!--/container -->
    </div><!--/H -->

    <!-- ********** 
    INDIVIDUAL PROJECT ********** -->
<!--     <section id="pplanter"></section> -->
    <div id="proj">
      <div class="container">
        <div class="row mt">
          <div class="col-md-12">
            <h3 class="centered">The Question</h3>
            <h6 class="mt">In 10 years or so…we will all go around in a world that will respond to our mental commands. Fed by data wirelessly streaming in from a few freckle-size sensors embedded in your scalp, your stereo will know when you are feeling blue and what sort of music cheers you up. Movies will know when you are getting bored and cut to the action. Car advertisers will know when you are feeling the need for speed. Your doctor will know when you are depressed. Doors will open at your mental command.</h6> 
            <h3 class="text-right small">– Tan Le (CEO of Emotiv) in an interview <br>with David H. Freedman, 2008</h3>


            <p class="mt">Often we read or hear futuristic predictions that just seem so far fetched that we instantly categorize them as fictitious, falling outside the realm of possibility.  Occasionally though, (especially in recent times with our exponentially growing appetite for technology) it’s worth asking the question ‘what if?’.  For instance, if Tan Le’s prophecy came to fruition, what would that really mean for us? How would it affect the way that we interact with each other and the world around us?    
            </p>

            <p class="mt">Given the current state of our technology, how feasible does a prediction like this seem? Hundreds of different sensors are currently being used in the built environment, ranging from infrared and photo sensors to detect light and motion to humistor and thermistor sensors to detect environmental temperature and humidity.  We are in the process of building the Internet of Things through this embedded computation, with sensor feedback networks forming the backbone of responsive and automated environments.  
            </p>
          </div>
        </div>
      </div>

     <!-- ********** QUOTE ********** -->           
<!--             <h5 class="mt">100% of Google survey respondents are upset about the amount of human waste found on streets/sidewalks.</h5>
            <h3 class="text-right small"> --Public Toilet Project Masterplan, Hyphae Design Lab</h3>           
 -->

      <div class="container-fluid">
        <div class="row mt">
          <img src="assets/img/brainwave/brainwave_sensor.png" class="img-fullWidth">
        </div>
      </div>     

      <div class="container">
        <div class="row mt">
          <div class="col-md-12">
            <p class="mt">Lately, we have also seen an increase in more nuanced biophysical sensors that detect heart rate, hand gestures or eye movement etc.  Many futurists such as Tan Le, posit that technologies such as electroencephalography (EEG), which detects brainwave activity are the next step in this lineage- the input modality of the future. While this notion is easily conflated with science fiction, the rise of consumer grade devices like those of Neurosky or Emotiv speaks to the plausibility of using BCI technology as an input modality. If this possibility became a reality, how could it affect the way us users engage and interact with our environments, be they physical, augmented or virtual?    
            </p>
            <p class="mt">It was this broad question that formed the basis for my thesis at the Center for Environmental Design at UC Berkeley.   At that point in time I was living with a neuroscientist and many of our conversations were centered on what we both saw as the intersection of our disciplines, mine being architecture.  I was fascinated by how conscious (cognitive) and subconscious (affective) input could be used as a way to modulate our physical, augmented or virtual environments.  It was this acute interest that inspired this research thesis.  What ensued was an exploratory process where I investigated the technology and it’s use, developed a test use case and user profile, experimented with a consumer grade device and envisioned future implementation scenarios.    
            </p>
          </div>
        </div>
      </div>

      <div class="container-fluid">
        <div class="row mt">
          <div class="col-md-4 no-pad">
            <img src="assets/img/brainwave/brainwave_device1.jpg" class="img-fullWidth">
          </div>
          <div class="col-md-4 no-pad">
            <img src="assets/img/brainwave/brainwave_device2.jpg" class="img-fullWidth">
          </div>
          <div class="col-md-4 no-pad">
            <img src="assets/img/brainwave/brainwave_device3.jpg" class="img-fullWidth">
          </div>          
        </div>
      </div> 

      <div class="container">
        <div class="row mt">
          <div class="col-md-12">                   
            <p class="mt">This project wasn’t typical architectural design, yet I truly believe that the responsiveness of future constructed environments will be reliant on the data provided sensor feedback networks.  Sensors that provide such nuanced information, especially pertaining to human intent and emotion, may enable the creation of environments that are truly user centered – the ultimate goal of humanist architecture.   
            </p>                                                
          </div>
        </div>
      </div>


    <!-- ********** USERS ********** -->     
      <div class="container-fluid bgcol">      
<!--         <div class="container">  -->       
          <div class="row mt">
            <div class="col-md-12 col-lg-6">
              <img src="assets/img/brainwave/brainwave_user.png" class="img-fullWidth">
            </div>                
            <div class="col-md-12 col-lg-6 pad pad-text mb mt">
              <h3>The User | Use case </h3>
              <p>Brain-computer interfacing enables a direct communication link between an external device and the brain and can provide us with information on a user’s emotional state, preemptive action, intent and personal choice.  As the data generated by this sensor is highly personal, focusing on a single user seemed like the simplest way to explore how using BCI as an input modality could alter or define interactions in day-to-day life.    
              </p>
<!--               <h3 class="centered mt">The Use Case</h3> -->
              <p>Given that I was studying architecture at the time, I selected John, a graduate architecture student as the focus of my user study.  It was important that the use case reflect the typical behaviour of a broader demographic, so decided to limit the study to the most common environment for this particular user, an architecture school building.     
              </p>                                                          
            </div>
          </div> 
      </div>

      <div class="container">  
        <div class= "row mt">
          <div class="col-md-12">
            <p class="mt">By examining the types of activities architecture students typically engage in and where these typically occur within an architecture school building, I was able to limit the case study to areas with the most predictable use: circulation space (corridor), personal workspace (studio), presentation space (gallery), social space (courtyard) and teaching space (classroom).
            </p>
            <p class="mt">The experiential case study I generated examines the day of a typical user in two future phases and looks at their behavior in each of the spaces outlined above.
            Typical activities in these typologies were storyboarded to explore the range of ways that this technology could affect human-human and human-environment interaction.</p>
          </div>
        </div>
      </div>


       

    <!-- ********** TEAM ********** -->
      <div class="container">  
        <div class= "row mt">
          <div class="col-md-12">
            <h3 class="centered">My Role | Methodology</h3>
            <p class="mt">When I began this study, I had little to no familiarity with UX research as a discipline. Over its duration however, I came to realize that the aspect of environmental design that interested me the most was perhaps not the designed environments themselves, but the way people interact with and within them.  I was already a lifetime subscriber to the humanist architecture of greats like Alvar Aalto and Charles and Ray Eames, which allowed the needs of the user to drive the design of objects and environments alike.  </p>
            <p class="mt">It seemed to me that if we were able to calibrate environments at an individual grain, we could inhabit truly humanist environments.  Thinking along these lines lead me to look at typical UX research practices, which informed my case study and experiment design.   Interaction design tools and methodologies like storyboarding were also used extend the user case study to future scenarios. </p>
          </div>
        </div>
      </div>

      <div class="container-fluid">  
        <div class= "row mt">
          <img src="assets/img/brainwave/brainwave_mindmap.jpg" class="img-fullWidth">
        </div>
      </div>
      <div class="container">  
        <div class= "row mt">
          <div class="col-md-12">
            <p class="mt">While I was the primary researcher on this project, it would have probably turned out a lot worse if not for the support and assistance from a number of people. Prof Susan Ubbelohde and Prof. Cris Benton were my main advisors with architecture and environmental design. Other advisors like Chris Holgraf  (neuroscience), Dave Lu (computer science) and John Faichney (computational design) brought much needed insight. </p>
          </div>
        </div>
      </div>

    <!-- ********** MAIN CONSTRAINTS ********** -->
      <div class ="container"> 
        <div class= "row mt">
          <div class="col-md-12">
            <h3 class="centered">Constraints</h3>                               
            <p class="mt">Like any interesting project, there were a lot of them! I had intended this preliminary study to be the precursor to a PhD on the same topic, so the focus was mainly on developing a case for future research through familiarizing myself with the technology and case study development. I repeatedly encountered technological challenges, having no formal programming training but was able to get through with basic python and javascript knowledge.
            </p>
            <p class="mt">I also ran into numerous issues with consistency in my experiments with the Emotiv headset.  Test subjects had to be trained and training periods varied from person to person.  Recreating the test conditions for each subject proved difficult as well as this was really the first time I had worked on behavioural testing. 
            </p>                          
          </div>
        </div>
      </div>   

    <!-- ********** DESIGN PROCESS ********** -->
      <div class="container"> 
        <div class="row mt ">
          <h3 class="centered">Investigative Process</h3>
          <p class="mt">My investigative process could be loosely grouped into research, experimentation and storyboarding. I initially looked into how EEG works and the history of technology, for both consumer and medical grade devices.  I then delved into how EEG was being used outside of the neuronal sciences and used these case studies as the basis for defining environmental design applications. Testing a consumer grade device was also critical to this research project as it was necessary to ascertain how reliable the present technology was.  Finally I drew upon predictions made regarding future capabilities of BCI and automated architecture to develop and storyboard environment/user interaction for my specified use case.  
          </p>
        </div>
      </div>

      <div class="container-fluid img-scroll mt">  
        <div class= "row mt">
          <img src="assets/img/brainwave/brainwave_timeline.jpg" class="">
        </div>
      </div>

      <div class="container-fluid bgcol hidden-xs">  
          <div class="row" style="padding:1% 5% 1% 5%;">
              <img class= "img-fullWidth" src="assets/img/brainwave/brainwave_matrix.png">
          </div>
      </div>

      <div class="container-fluid bgcol"> 
        <div class="row">
          <div class="col-md-12 col-lg-6">
            <img class= "img-fullWidth" src="assets/img/brainwave/brainwave_emotiv.png">          
          </div>          
          <div class="col-md-12 col-lg-6  mt pad pad-text">
            <h3 class="centered">Experiments</h3>
            <p class="mt mb">I wanted to test both the capabilities and reliability of a consumer grade EEG device. Using an Emotiv Epoc I carried out a series of experiments with Processing, mapping the output of the device (cognitive and affective states) to certain functions that would change colour or images on screen. In one of the earliest experiments that worked, the test subject was able to cycle through a series of animals by thinking “right” or “left”, cognitive states that were decipherable by the EEG headset.  Subsequent tests that involved changing animals based on emotional response had mixed results, however showed that it was possible to use affective input. Two experiments using light color and temperature were designed to test how the BCI input could be used to control real world conditions. 
            </p>
          </div>
        </div>
      </div>

      <div class="container">  
        <div class="row mt">  
          <div class="col-md-12">
            <h6 class="mt">Testing cognitive input </h6>
            <p>The first light experiment was focused on cognitive input and again required mapping the think “left”, think “right” feedback to different functions.  I was interested in how EEG could be used as a way to consciously control environments, like a highly nuanced light switch that could be calibrated to satisfy the needs of each individual.  </p>                          
            <h6 class="mt">Changing RGB values of a light</h6>
            <p>This experiment explored the ability of BCI to control environmental conditions. The test subject was encouraged to focus on a set colour: red, green or blue. Input from and an Emotiv EPOC headset was routed from the Emotiv controller software to Processing via MindYourOSC's. The headset was calibrated to register the test subjects neural activity when thinking of these set colours. Processing was then used to modulate an LED strip in the lightbox through an Arduino microcontroller.</p>
          </div>         
        </div>
      </div>      

      <div class="container-fluid">  
        <div class="row mt">
          <div class="col-md-12 centered">
            <img class= "img-fullWidth" src="assets/img/brainwave/brainwave_rgb.png" style="border:1px solid;">
          </div>
        </div>
      </div>

      <div class="container">  
        <div class="row mt">  
          <div class="col-md-12">        
            <h6 class="mt">Testing affective input </h6>
            <p>In psychology, affect refers to the experience of feeling or emotion and is considered an integral component in our interaction with external stimuli. Sensing emotion through BCI could allow our environments to function as indicators of conscious or unconscious emotional state, facilitating greater transparency in our interpersonal and social interactions; allowing fundamental human reactions to be made legible through environmental conditions. </p>
          </div>         
        </div>
        <div class="row mt">  
          <div class="col-md-12">        
            <h6 class="mt">The Kruithof Curve </h6>
            <p>Following a similar process to the brain controlled light box experiment, the Kruithof curve experiment also looks at how light conditions can be modulated
            with BCI input. The Kruithof curve posits that an optimal light temperature exists between warm and cool. The Emotiv headset is able to record levels of frustration and this quality was used as the determining factor in a feedback loop to generate an optimal temperature of light. Using Processing, the gradient of warm to cool light was cycled through while being projected onto the test subject. The subjects increased level of frustration was used to cull specific colours from the loop until only one colour was left.
            </p>
          </div>         
        </div>        
      </div>      

      <div class="container-fluid">  
        <div class="row mt">
          <div class="col-md-12 centered">
            <img class= "img-fullWidth" src="assets/img/brainwave/brainwave_kruitof.png" style="border:1px solid;">
          </div>
        </div>
      </div>


      <div class="container">  
        <div class="row mt">  
          <div class="col-md-12 mb">        
            <h3 class="centered">Predicting Future Use</h3>
            <p class="mt">Thought the experiments I carried out helped me better understand the consumer grade technology and it’s current capabilities, the larger question in my thesis really pertained to future applications. My testing lead me to conclude that while EEG technology is still at an early stage, real potentials exist for it’s adoption as an input modality for HCI and also the built environment.  One future application of BCI, as a control mechanism for environments, is fairly straightforward. For instance, a user walks towards a door, wants the door to open and the door opens. There’s a direct cause–effect relationship that is predictable at an individual level and complex when scaled to include multiple users however dealing with that issue was really another question entirely.  What was unclear to me and perhaps more interesting were the ways affective feedback could be used and reflected in our environments as this is something that doesn’t currently happen but could be an opportunity for novel human-environment interaction.  With this in mind, four areas of potential use were identified: input modality; human-environment interaction; climate control; and human-human interaction. 
            </p>
          </div>         
        </div>
      </div>  


      <div class="container-fluid">        
        <div class="row centered mt mb">
          <img class= "img-fullWidth" src="assets/img/brainwave/brainwave_potential.png">
        </div>
      </div>

      <div class="container">  
        <div class="row mt">  
          <div class="col-md-12">        
            <h3 class="centered">Storyboarding Interaction</h3>
            <p class="mt">In this case study, storyboarding was used to explore the affective, as opposed to cognitive, potential that this technology could bring to responsive environments.  I was excited by the potential BCI brings to converting environments into new platforms for social engagement and interaction, independent of a users ability to communicate through traditional means (speech, body language). The issues of ubiquitous environments were also challenged through encouraging personalization and imprinting. In addition to such expressive qualities, the incorporation of affect could also allow environments to behave empathetically, furthering the work of architects such as Alvar Aalto who aspired to create buildings that were sympathetic to human needs. Both utopic and dystopic possibilities were explored.   
            
            </p>
          </div>         
        </div>
      </div>  


      <div class="container-fluid bgcol">  
        <div class="row mt mb">
          <div id="myCarousel1" class="carousel slide col-md-12 col-lg-6" data-ride="carousel">
            <!-- Indicators -->
<!--             <ol class="carousel-indicators">
              <li data-target="#myCarousel1" data-slide-to="0" class=""></li>
              <li data-target="#myCarousel1" data-slide-to="1" class="active"></li>
              <li data-target="#myCarousel1" data-slide-to="2"></li>
            </ol> -->
            <div class="carousel-inner" role="listbox">
            </div>
            <a class="left carousel-control" href="#myCarousel1" role="button" data-slide="prev">
              <span class="glyphicon glyphicon-chevron-left" aria-hidden="true"></span>
              <span class="sr-only">Previous</span>
            </a>
            <a class="right carousel-control" href="#myCarousel1" role="button" data-slide="next">
              <span class="glyphicon glyphicon-chevron-right" aria-hidden="true"></span>
              <span class="sr-only">Next</span>
            </a>
          </div>
          <div class="col-md-12 col-lg-6 pad pad-text">
            <h6 class="mt">Phase 1</h6>
            <p>Phase 1 examines the not too distant future, under the presumption that BCI technology is being ubiquitously used. Architecture and it’s interactive capabilities at this point are similar to what we know today.  Interactive systems are used as an overlay e.g. augmented reality, and are not really embedded within the structural or tectonic language of the built environment. The EEG acquisition device is capable of radings a number of affective and cognitive states yet is not highly accurate.  The scenarios developed for phase 1, assume the use of BCI input in conjunction with other technologies such as eye or motion tracking to relate mental states to environmental experiences. </p>
          </div>
        </div>
      </div>


      <div class="container-fluid bgcol">  
        <div class="row mt mb">
          <div id="myCarousel2" class="carousel slide col-md-12 col-lg-6" data-ride="carousel">
            <!-- Indicators -->
<!--             <ol class="carousel-indicators">
              <li data-target="#myCarousel2" data-slide-to="0" class=""></li>
              <li data-target="#myCarousel2" data-slide-to="1" class="active"></li>
              <li data-target="#myCarousel2" data-slide-to="2"></li>
            </ol> -->
            <div class="carousel-inner" role="listbox">
            </div>
            <a class="left carousel-control" href="#myCarousel2" role="button" data-slide="prev">
              <span class="glyphicon glyphicon-chevron-left" aria-hidden="true"></span>
              <span class="sr-only">Previous</span>
            </a>
            <a class="right carousel-control" href="#myCarousel2" role="button" data-slide="next">
              <span class="glyphicon glyphicon-chevron-right" aria-hidden="true"></span>
              <span class="sr-only">Next</span>
            </a>
          </div>
          <div class="col-md-12 col-lg-6 pad pad-text">
            <h6 class="mt">Phase 2</h6>
            <p>Phase 2 is premised on the ability of the built environment to be fully reconfigurable and completely interactive. The EEG acquisition device in this phase is much more sophisticated than its predecessors, with the ability to read multiple discrete and complex emotional states and desires. In these scenarios, there is an assumption that the architecture is able to change and adapt into a variety of preconfigured states, generated both through programming and environmental heuristics.  Theses examples aim to explore how environmental configuration could be modulated by BCI input. </p>
          </div>
        </div>
      </div>

 


<!--         CLOSING COMMENTS -->
      <div class="container">
        <div class="row mt">
          <div class="col-md-12">
            <h3 class="centered">In retrospect</h3>
            <p>Should we listen to the exponents of brain-computer interfacing in their resolute belief that the incorporation of brainwave sensor input into our environment controls has the potential to revolutionize the way we design and interact with the built environment? Maybe. This study demonstrated for me that the possibilities for environmental design are truly vast, exciting and possibly beyond our imaginings.  While the technology is in formative stages at present,  developments are being made consistently in the neuronal sciences that will filter out into the consumer market. 
            </p>
            <p>It's possible that as out understanding of the human brain improves with technology like optogenetics and the mapping of the human connectome, the adoption of BCI as a widely used sensor is perhaps more plausible.  It’s clear the Tan Le’s prediction was an optimistic one and the timeframe she placed was truly unrealistic however that doesn’t necessarily negate her prophecy.  Perhaps one day we’ll be able to experience BCI controlled environments firsthand but till then it would be wise to prevent our current technological limitations from constraining our visions of the future. 
            </p>
          </div>
        </div>                               
      </div>

<!--         NEXT PROJECT -->      
      <div id="workproj">  
        <div class="container mt">
          <div class="row mt mb">
            <div class="col-md-12">
              <h3 class="centered small">NEXT PROJECT</h3>
              <hr align="center" class="divider"> 
              <h2 class="centered"><a href="secretscoop.html">Secret Scoop : UI redesign</a></h2>            
            </div>
          </div>                               
        </div>
      </div>


    </div>      

    <!-- ********** FOOTER ********** -->
    <section id="contact"></section>
    <div id="f">
      <div class="container-fluid mt">
        <div class="row centered mt" style="background-color:#E9E9E9;">
          <h3 class="small">You can contact me anytime! </h3>
          <h3 class="small"><a href="mailto:hello@anastasia.io">hello AT anastasia.io</h3>
          <h2 style="font-size:50px;">
            <a href="https://twitter.com/AVmakesthings"><i class="ion-social-twitter"></i></a>
            <a href="https://www.linkedin.com/pub/anastasia-victor-faichney/19/965/8b1"><i class="ion-social-linkedin"></i></a>
            <a href="https://instagram.com/anastasiavictor/"><i class="ion-social-instagram"></i></a>
            <a href="https://www.pinterest.com/avmakesthings/"><i class="ion-social-pinterest"></i></a>           
          </h2>
          <h4 class="small">&copy; 2015 Anastasia Victor</h4>
          <h4 class="small">Built with Bootstrap</h4>          
        </div><!--/row-->
      </div><!--/container-->
    </div><!--/F--> 

  

    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="assets/js/jquery.min.js"></script>
    <script src="assets/js/jquery.ba-throttle-debounce.js"></script>    
    <script src="assets/js/bootstrap.min.js"></script>
    <script src="assets/js/retina-1.1.0.js"></script>
    <script src="assets/js/classie.js"></script>
    <script src="assets/js/smoothscroll.js"></script>
    <script src="assets/js/main.js"></script>

    // <script>
    //   $('.carousel').carousel({
    //       interval: 4000,
    //       wrap: false,
    //       pause: "hover"
    //   })
    // </script> 



  </body>
</html>